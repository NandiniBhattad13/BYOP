{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2617192,"sourceType":"datasetVersion","datasetId":1590810}],"dockerImageVersionId":30302,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!ls /kaggle/input/emotion-dataset/","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:31:04.130362Z","iopub.execute_input":"2023-12-20T09:31:04.130780Z","iopub.status.idle":"2023-12-20T09:31:05.093741Z","shell.execute_reply.started":"2023-12-20T09:31:04.130742Z","shell.execute_reply":"2023-12-20T09:31:05.092510Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"test.csv  training.csv\tvalidation.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom IPython.display import display\nimport warnings; warnings.filterwarnings('ignore')\n\nvalidation = pd.read_csv('/kaggle/input/emotion-dataset/validation.csv')\ntrain = pd.read_csv('/kaggle/input/emotion-dataset/training.csv')\ntest = pd.read_csv('/kaggle/input/emotion-dataset/test.csv')\n\nprint('Dataset information:')\nprint(f'Training data: {train.shape}')\nprint(f'Validation data: {validation.shape}')\nprint(f'Test data: {test.shape}')","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:31:05.095942Z","iopub.execute_input":"2023-12-20T09:31:05.096263Z","iopub.status.idle":"2023-12-20T09:31:05.202260Z","shell.execute_reply.started":"2023-12-20T09:31:05.096234Z","shell.execute_reply":"2023-12-20T09:31:05.201267Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Dataset information:\nTraining data: (16000, 2)\nValidation data: (2000, 2)\nTest data: (2000, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"display(train.head(10))","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:31:05.203478Z","iopub.execute_input":"2023-12-20T09:31:05.203790Z","iopub.status.idle":"2023-12-20T09:31:05.222723Z","shell.execute_reply.started":"2023-12-20T09:31:05.203762Z","shell.execute_reply":"2023-12-20T09:31:05.221751Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"                                                text  label\n0                            i didnt feel humiliated      0\n1  i can go from feeling so hopeless to so damned...      0\n2   im grabbing a minute to post i feel greedy wrong      3\n3  i am ever feeling nostalgic about the fireplac...      2\n4                               i am feeling grouchy      3\n5  ive been feeling a little burdened lately wasn...      0\n6  ive been taking or milligrams or times recomme...      5\n7  i feel as confused about life as a teenager or...      4\n8  i have been with petronas for years i feel tha...      1\n9                                i feel romantic too      2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>i didnt feel humiliated</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i can go from feeling so hopeless to so damned...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>im grabbing a minute to post i feel greedy wrong</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i am ever feeling nostalgic about the fireplac...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i am feeling grouchy</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ive been feeling a little burdened lately wasn...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>ive been taking or milligrams or times recomme...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>i feel as confused about life as a teenager or...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>i have been with petronas for years i feel tha...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>i feel romantic too</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import Dataset,DatasetDict,Features,Value,ClassLabel\n\n# Don't forget the class label data\nclass_names = ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\nft = Features({'text': Value('string'), 'label': ClassLabel(names=class_names)})\n\n# Combine Multiple Datasets \nemotions = DatasetDict({\n    \"train\": Dataset.from_pandas(train,features=ft),\n    \"test\": Dataset.from_pandas(test,features=ft),\n    \"validation\": Dataset.from_pandas(validation,features=ft)\n    })\nemotions","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:31:05.224865Z","iopub.execute_input":"2023-12-20T09:31:05.225164Z","iopub.status.idle":"2023-12-20T09:31:06.081690Z","shell.execute_reply.started":"2023-12-20T09:31:05.225137Z","shell.execute_reply":"2023-12-20T09:31:06.080712Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 16000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 2000\n    })\n    validation: Dataset({\n        features: ['text', 'label'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# Convert Dataset to DataFrame (don't forget to reset)\nemotions.set_format(type=\"pandas\")\ndf = emotions[\"train\"][:]\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:31:06.083047Z","iopub.execute_input":"2023-12-20T09:31:06.083617Z","iopub.status.idle":"2023-12-20T09:31:06.113026Z","shell.execute_reply.started":"2023-12-20T09:31:06.083576Z","shell.execute_reply":"2023-12-20T09:31:06.111838Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"                                                    text  label\n0                                i didnt feel humiliated      0\n1      i can go from feeling so hopeless to so damned...      0\n2       im grabbing a minute to post i feel greedy wrong      3\n3      i am ever feeling nostalgic about the fireplac...      2\n4                                   i am feeling grouchy      3\n...                                                  ...    ...\n15995  i just had a very brief time in the beanbag an...      0\n15996  i am now turning and i feel pathetic that i am...      0\n15997                     i feel strong and good overall      1\n15998  i feel like this was such a rude comment and i...      3\n15999  i know a lot but i feel so stupid because i ca...      0\n\n[16000 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Add label data to dataframe\ndef label_int2str(row):\n    return emotions[\"train\"].features[\"label\"].int2str(row)\n\ndf[\"label_name\"] = df[\"label\"].apply(label_int2str)\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:31:06.114206Z","iopub.execute_input":"2023-12-20T09:31:06.114465Z","iopub.status.idle":"2023-12-20T09:31:06.180788Z","shell.execute_reply.started":"2023-12-20T09:31:06.114440Z","shell.execute_reply":"2023-12-20T09:31:06.179871Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"                                                    text  label label_name\n0                                i didnt feel humiliated      0    sadness\n1      i can go from feeling so hopeless to so damned...      0    sadness\n2       im grabbing a minute to post i feel greedy wrong      3      anger\n3      i am ever feeling nostalgic about the fireplac...      2       love\n4                                   i am feeling grouchy      3      anger\n...                                                  ...    ...        ...\n15995  i just had a very brief time in the beanbag an...      0    sadness\n15996  i am now turning and i feel pathetic that i am...      0    sadness\n15997                     i feel strong and good overall      1        joy\n15998  i feel like this was such a rude comment and i...      3      anger\n15999  i know a lot but i feel so stupid because i ca...      0    sadness\n\n[16000 rows x 3 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"df[\"Words Per Tweet\"] = df[\"text\"].str.split().apply(len)\nprint(df.head())","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:31:06.182051Z","iopub.execute_input":"2023-12-20T09:31:06.182408Z","iopub.status.idle":"2023-12-20T09:31:06.247353Z","shell.execute_reply.started":"2023-12-20T09:31:06.182372Z","shell.execute_reply":"2023-12-20T09:31:06.246211Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"                                                text  label label_name  \\\n0                            i didnt feel humiliated      0    sadness   \n1  i can go from feeling so hopeless to so damned...      0    sadness   \n2   im grabbing a minute to post i feel greedy wrong      3      anger   \n3  i am ever feeling nostalgic about the fireplac...      2       love   \n4                               i am feeling grouchy      3      anger   \n\n   Words Per Tweet  \n0                4  \n1               21  \n2               10  \n3               18  \n4                4  \n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\nmodel_ckpt = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)\ntokenizer\n","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:31:06.248813Z","iopub.execute_input":"2023-12-20T09:31:06.249265Z","iopub.status.idle":"2023-12-20T09:31:08.994735Z","shell.execute_reply.started":"2023-12-20T09:31:06.249218Z","shell.execute_reply":"2023-12-20T09:31:08.993655Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9f8873d3d2a41a7a72f781accc78a16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebc2bc4987864aa3b6a796e5dac36c99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"653f816a94c44c438196b03f00d0c190"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5a91716284444a4a60aeb283f4f21d7"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"PreTrainedTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"},"metadata":{}}]},{"cell_type":"code","source":"emotions.reset_format()","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:31:08.996223Z","iopub.execute_input":"2023-12-20T09:31:08.997165Z","iopub.status.idle":"2023-12-20T09:31:09.002778Z","shell.execute_reply.started":"2023-12-20T09:31:08.997132Z","shell.execute_reply":"2023-12-20T09:31:09.001811Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Tokenisation function\ndef tokenise(batch):\n    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n\n# Show the tokenised ids\nex_tokenised = tokenise(emotions[\"train\"][:2])","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:31:09.007499Z","iopub.execute_input":"2023-12-20T09:31:09.007771Z","iopub.status.idle":"2023-12-20T09:31:09.022290Z","shell.execute_reply.started":"2023-12-20T09:31:09.007747Z","shell.execute_reply":"2023-12-20T09:31:09.021324Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"ex_tokenised['attention_mask']","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:31:09.023568Z","iopub.execute_input":"2023-12-20T09:31:09.023930Z","iopub.status.idle":"2023-12-20T09:31:09.032423Z","shell.execute_reply.started":"2023-12-20T09:31:09.023894Z","shell.execute_reply":"2023-12-20T09:31:09.031423Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"[[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]"},"metadata":{}}]},{"cell_type":"code","source":"emotions_encoded = emotions.map(tokenise, batched=True, batch_size=None)\nprint(emotions_encoded[\"train\"].column_names)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:31:09.033702Z","iopub.execute_input":"2023-12-20T09:31:09.034055Z","iopub.status.idle":"2023-12-20T09:31:11.283722Z","shell.execute_reply.started":"2023-12-20T09:31:09.034011Z","shell.execute_reply":"2023-12-20T09:31:11.282573Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03a9aa9eb3d3470e97c3ca0e58591e46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"927903b249c549cf9123cf36ee2f445e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44ff83c2c00f4aa096d943851ddb3d97"}},"metadata":{}},{"name":"stdout","text":"['text', 'label', 'input_ids', 'attention_mask']\n","output_type":"stream"}]},{"cell_type":"code","source":"import warnings; warnings.filterwarnings('ignore')\nfrom transformers import AutoModel\nimport torch\n\nmodel_ckpt = \"distilbert-base-uncased\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = AutoModel.from_pretrained(model_ckpt).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:31:11.285053Z","iopub.execute_input":"2023-12-20T09:31:11.285372Z","iopub.status.idle":"2023-12-20T09:31:24.500576Z","shell.execute_reply.started":"2023-12-20T09:31:11.285342Z","shell.execute_reply":"2023-12-20T09:31:24.499475Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec81a0365bd44d4f9b79e6547de653aa"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"def extract_hidden_states(batch):\n    \n    # Place model inputs on the GPU\n    inputs = {k:v.to(device) for k,v in batch.items()\n              if k in tokenizer.model_input_names}\n    \n    # Extract last hidden states\n    with torch.no_grad():\n        last_hidden_state = model(**inputs).last_hidden_state\n        \n    # Return vector for [CLS] token\n    return {\"hidden_state\": last_hidden_state[:,0].cpu().numpy()}","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:31:24.501996Z","iopub.execute_input":"2023-12-20T09:31:24.502317Z","iopub.status.idle":"2023-12-20T09:31:24.509051Z","shell.execute_reply.started":"2023-12-20T09:31:24.502285Z","shell.execute_reply":"2023-12-20T09:31:24.508069Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"emotions_encoded.set_format(\"torch\",\n                            columns=[\"input_ids\", \"attention_mask\", \"label\"])\nemotions_encoded","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:31:24.510476Z","iopub.execute_input":"2023-12-20T09:31:24.510756Z","iopub.status.idle":"2023-12-20T09:31:24.527547Z","shell.execute_reply.started":"2023-12-20T09:31:24.510730Z","shell.execute_reply":"2023-12-20T09:31:24.526655Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 16000\n    })\n    test: Dataset({\n        features: ['text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 2000\n    })\n    validation: Dataset({\n        features: ['text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"emotions_hidden = emotions_encoded.map(extract_hidden_states, batched=True)\nemotions_hidden[\"train\"].column_names","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:31:24.528915Z","iopub.execute_input":"2023-12-20T09:31:24.529978Z","iopub.status.idle":"2023-12-20T09:31:49.859993Z","shell.execute_reply.started":"2023-12-20T09:31:24.529938Z","shell.execute_reply":"2023-12-20T09:31:49.859009Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/16 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7989f95aee7b459296554f69e29c3f29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41526c3f81614304851a99a036a9656d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ddd6fb64ee94a128993d67876e12a62"}},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"['text', 'label', 'input_ids', 'attention_mask', 'hidden_state']"},"metadata":{}}]},{"cell_type":"code","source":"X_train = np.array(emotions_hidden[\"train\"][\"hidden_state\"])\nX_valid = np.array(emotions_hidden[\"validation\"][\"hidden_state\"])\ny_train = np.array(emotions_hidden[\"train\"][\"label\"])\ny_valid = np.array(emotions_hidden[\"validation\"][\"label\"])\nprint(f'Training Dataset: {X_train.shape}')\nprint(f'Validation Dataset {X_valid.shape}')","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:31:49.861059Z","iopub.execute_input":"2023-12-20T09:31:49.861326Z","iopub.status.idle":"2023-12-20T09:31:50.016759Z","shell.execute_reply.started":"2023-12-20T09:31:49.861301Z","shell.execute_reply":"2023-12-20T09:31:50.015747Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Training Dataset: (16000, 768)\nValidation Dataset (2000, 768)\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:31:50.017949Z","iopub.execute_input":"2023-12-20T09:31:50.018266Z","iopub.status.idle":"2023-12-20T09:31:50.027718Z","shell.execute_reply.started":"2023-12-20T09:31:50.018220Z","shell.execute_reply":"2023-12-20T09:31:50.026843Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"array([[-0.11675112,  0.0985712 , -0.1296294 , ...,  0.05871103,\n         0.35432687,  0.4042069 ],\n       [-0.03236276, -0.032315  , -0.19572599, ..., -0.17465746,\n         0.35463798,  0.30276588],\n       [ 0.03974653,  0.20223357,  0.14227144, ..., -0.11406811,\n         0.33937755,  0.39583102],\n       ...,\n       [-0.00339851, -0.09585507,  0.05843527, ..., -0.04272686,\n         0.24959192,  0.30761606],\n       [ 0.06660312,  0.17334336,  0.12896673, ...,  0.06118574,\n         0.29038203,  0.46844172],\n       [ 0.0166881 ,  0.10127111, -0.00731735, ..., -0.06493614,\n         0.34540522,  0.21993555]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"import warnings; warnings.filterwarnings('ignore')\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.manifold import TSNE\n\n# Scale the data\nX_scaled = MinMaxScaler().fit_transform(X_train)\n\n# lower dimension transformation\nmodel = TSNE(n_components=2).fit(X_scaled)\n\n# Create a df of 2D embeddings\ndf_embedding = pd.DataFrame(model.embedding_, columns=[\"X\", \"Y\"])\ndf_embedding[\"label\"] = y_train","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:31:50.029003Z","iopub.execute_input":"2023-12-20T09:31:50.029285Z","iopub.status.idle":"2023-12-20T09:33:46.656050Z","shell.execute_reply.started":"2023-12-20T09:31:50.029259Z","shell.execute_reply":"2023-12-20T09:33:46.655076Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression as LR\n\n# We increase `max_iter` to guarantee convergence\nlr_clf = LR(max_iter = 2000,C=1.0, penalty='l2', solver='lbfgs')\nlr_clf.fit(X_train, y_train)\ny_preds = lr_clf.predict(X_valid)\nprint(f'accuracy: {lr_clf.score(X_valid, y_valid)}')","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:33:46.657580Z","iopub.execute_input":"2023-12-20T09:33:46.658033Z","iopub.status.idle":"2023-12-20T09:35:58.365310Z","shell.execute_reply.started":"2023-12-20T09:33:46.657988Z","shell.execute_reply":"2023-12-20T09:35:58.364028Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"accuracy: 0.6335\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nnum_labels = 6\n\nmodel_ckpt = \"distilbert-base-uncased\"\nmodel = (AutoModelForSequenceClassification\n         .from_pretrained(model_ckpt, \n                          num_labels=num_labels)\n         .to(device))","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:35:58.366800Z","iopub.execute_input":"2023-12-20T09:35:58.367213Z","iopub.status.idle":"2023-12-20T09:35:59.615045Z","shell.execute_reply.started":"2023-12-20T09:35:58.367173Z","shell.execute_reply":"2023-12-20T09:35:59.614049Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\n\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    f1 = f1_score(labels, preds, average=\"weighted\")\n    acc = accuracy_score(labels, preds)\n    return {\"accuracy\": acc, \"f1\": f1}","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:35:59.616405Z","iopub.execute_input":"2023-12-20T09:35:59.617267Z","iopub.status.idle":"2023-12-20T09:35:59.623694Z","shell.execute_reply.started":"2023-12-20T09:35:59.617224Z","shell.execute_reply":"2023-12-20T09:35:59.622775Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\nbs = 64 # batch size\nlogging_steps = len(emotions_encoded[\"train\"]) // bs\nmodel_name = f\"{model_ckpt}-finetuned-emotion\"\ntraining_args = TrainingArguments(output_dir=model_name,\n                                  num_train_epochs=3,             \n                                  learning_rate=2e-5,             \n                                  per_device_train_batch_size=bs, \n                                  per_device_eval_batch_size=bs,  \n                                  weight_decay=0.01,\n                                  evaluation_strategy=\"epoch\",\n                                  disable_tqdm=False, \n                                  report_to=\"none\",\n                                  logging_steps=logging_steps,\n                                  push_to_hub=False,\n                                  log_level=\"error\")","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:35:59.624765Z","iopub.execute_input":"2023-12-20T09:35:59.625048Z","iopub.status.idle":"2023-12-20T09:36:03.826159Z","shell.execute_reply.started":"2023-12-20T09:35:59.625022Z","shell.execute_reply":"2023-12-20T09:36:03.825315Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import os\nfrom transformers import Trainer\nos.environ['WANDB_DISABLED'] = 'true'\n\ntrainer = Trainer(model=model, args=training_args,\n                  compute_metrics=compute_metrics,\n                  train_dataset=emotions_encoded[\"train\"],\n                  eval_dataset=emotions_encoded[\"validation\"],\n                  tokenizer=tokenizer)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:36:03.827360Z","iopub.execute_input":"2023-12-20T09:36:03.827995Z","iopub.status.idle":"2023-12-20T09:39:42.744954Z","shell.execute_reply.started":"2023-12-20T09:36:03.827964Z","shell.execute_reply":"2023-12-20T09:39:42.743893Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [750/750 03:36, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.820500</td>\n      <td>0.279120</td>\n      <td>0.912000</td>\n      <td>0.910830</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.209900</td>\n      <td>0.182544</td>\n      <td>0.926500</td>\n      <td>0.926731</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.145500</td>\n      <td>0.163653</td>\n      <td>0.935000</td>\n      <td>0.935259</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=750, training_loss=0.391937993367513, metrics={'train_runtime': 217.1267, 'train_samples_per_second': 221.069, 'train_steps_per_second': 3.454, 'total_flos': 1080514292544000.0, 'train_loss': 0.391937993367513, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"pred_output = trainer.predict(emotions_encoded[\"validation\"])\npred_output","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:39:42.746560Z","iopub.execute_input":"2023-12-20T09:39:42.746961Z","iopub.status.idle":"2023-12-20T09:39:45.470460Z","shell.execute_reply.started":"2023-12-20T09:39:42.746930Z","shell.execute_reply":"2023-12-20T09:39:45.469508Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [32/32 00:02]\n    </div>\n    "},"metadata":{}},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"PredictionOutput(predictions=array([[ 4.9806113 , -1.1787355 , -1.252648  , -1.2191039 , -1.315404  ,\n        -1.8504261 ],\n       [ 4.965513  , -1.191076  , -1.9389193 , -1.2089735 , -0.84556186,\n        -1.6520444 ],\n       [-1.1557474 ,  2.6984048 ,  3.4379437 , -0.9237739 , -1.293154  ,\n        -1.5881057 ],\n       ...,\n       [-1.2356148 ,  5.5525613 ,  0.14037505, -1.1087395 , -1.5180975 ,\n        -1.3508459 ],\n       [-1.6292329 ,  4.043329  ,  2.7634094 , -1.2158105 , -1.4717412 ,\n        -1.3610734 ],\n       [-1.4762266 ,  5.4794135 , -0.18959317, -1.4239289 , -1.4674346 ,\n        -0.26326662]], dtype=float32), label_ids=array([0, 0, 2, ..., 1, 1, 1]), metrics={'test_loss': 0.16365288197994232, 'test_accuracy': 0.935, 'test_f1': 0.9352585374471294, 'test_runtime': 2.7128, 'test_samples_per_second': 737.258, 'test_steps_per_second': 11.796})"},"metadata":{}}]},{"cell_type":"code","source":"print(f'Output Predition: {pred_output.predictions.shape}')\nprint(pred_output.predictions)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:39:45.471836Z","iopub.execute_input":"2023-12-20T09:39:45.472193Z","iopub.status.idle":"2023-12-20T09:39:45.478744Z","shell.execute_reply.started":"2023-12-20T09:39:45.472161Z","shell.execute_reply":"2023-12-20T09:39:45.477630Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Output Predition: (2000, 6)\n[[ 4.9806113  -1.1787355  -1.252648   -1.2191039  -1.315404   -1.8504261 ]\n [ 4.965513   -1.191076   -1.9389193  -1.2089735  -0.84556186 -1.6520444 ]\n [-1.1557474   2.6984048   3.4379437  -0.9237739  -1.293154   -1.5881057 ]\n ...\n [-1.2356148   5.5525613   0.14037505 -1.1087395  -1.5180975  -1.3508459 ]\n [-1.6292329   4.043329    2.7634094  -1.2158105  -1.4717412  -1.3610734 ]\n [-1.4762266   5.4794135  -0.18959317 -1.4239289  -1.4674346  -0.26326662]]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Decode the predictions greedily using argmax (highest value of all classes)\ny_preds = np.argmax(pred_output.predictions,axis=1)\nprint(f'Output Prediction:{y_preds.shape}')\nprint(f'Predictions: {y_preds}')","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:39:45.480095Z","iopub.execute_input":"2023-12-20T09:39:45.480415Z","iopub.status.idle":"2023-12-20T09:39:45.491532Z","shell.execute_reply.started":"2023-12-20T09:39:45.480385Z","shell.execute_reply":"2023-12-20T09:39:45.490487Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Output Prediction:(2000,)\nPredictions: [0 0 2 ... 1 1 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Show metrics of last iteration\npred_output.metrics","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:39:45.497568Z","iopub.execute_input":"2023-12-20T09:39:45.497974Z","iopub.status.idle":"2023-12-20T09:39:45.504479Z","shell.execute_reply.started":"2023-12-20T09:39:45.497943Z","shell.execute_reply":"2023-12-20T09:39:45.503594Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"{'test_loss': 0.16365288197994232,\n 'test_accuracy': 0.935,\n 'test_f1': 0.9352585374471294,\n 'test_runtime': 2.7128,\n 'test_samples_per_second': 737.258,\n 'test_steps_per_second': 11.796}"},"metadata":{}}]},{"cell_type":"code","source":"from torch.nn.functional import cross_entropy\n\ndef forward_pass_with_label(batch):\n    \n    # Place all input tensors on the same device as the model\n    inputs = {k:v.to(device) for k,v in batch.items()\n              if k in tokenizer.model_input_names}\n\n    with torch.no_grad():\n        output = model(**inputs)\n        pred_label = torch.argmax(output.logits, axis=-1)\n        loss = cross_entropy(output.logits, batch[\"label\"].to(device),\n                             reduction=\"none\")\n        \n    # Place outputs on CPU for compatibility with other dataset columns\n    return {\"loss\": loss.cpu().numpy(),\n            \"predicted_label\": pred_label.cpu().numpy()}\n\n# Convert our dataset back to PyTorch tensors\nemotions_encoded.set_format(\"torch\",\n                            columns=[\"input_ids\", \"attention_mask\", \"label\"])\n# Compute loss values\nemotions_encoded[\"validation\"] = emotions_encoded[\"validation\"].map(forward_pass_with_label,\n                                                                    batched=True, \n                                                                    batch_size=16)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:39:45.505804Z","iopub.execute_input":"2023-12-20T09:39:45.506127Z","iopub.status.idle":"2023-12-20T09:39:48.313005Z","shell.execute_reply.started":"2023-12-20T09:39:45.506099Z","shell.execute_reply":"2023-12-20T09:39:48.311928Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/125 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9775a83689de4f8cb12a29d7a07d263d"}},"metadata":{}}]},{"cell_type":"code","source":"emotions_encoded.set_format(\"pandas\")\ncols = [\"text\", \"label\", \"predicted_label\", \"loss\"]\ndf_test = emotions_encoded[\"validation\"][:][cols]\ndf_test[\"label\"] = df_test[\"label\"].apply(label_int2str)\ndf_test[\"predicted_label\"] = (df_test[\"predicted_label\"].apply(label_int2str))","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:39:48.314272Z","iopub.execute_input":"2023-12-20T09:39:48.314558Z","iopub.status.idle":"2023-12-20T09:39:48.346061Z","shell.execute_reply.started":"2023-12-20T09:39:48.314532Z","shell.execute_reply":"2023-12-20T09:39:48.345276Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"trainer.save_model()","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:39:48.347143Z","iopub.execute_input":"2023-12-20T09:39:48.347413Z","iopub.status.idle":"2023-12-20T09:39:48.950581Z","shell.execute_reply.started":"2023-12-20T09:39:48.347388Z","shell.execute_reply":"2023-12-20T09:39:48.949279Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\n# load from previously saved model\nclassifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-emotion\")\n\n# New unseen by model data\nnew_data = 'I love hardikj'","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:39:48.952133Z","iopub.execute_input":"2023-12-20T09:39:48.952479Z","iopub.status.idle":"2023-12-20T09:39:52.990175Z","shell.execute_reply.started":"2023-12-20T09:39:48.952444Z","shell.execute_reply":"2023-12-20T09:39:52.989103Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"preds = classifier.predict_proba(new_data)\nmax_label_index = preds.argmax()\nmax_score = preds[max_label_index]\nmax_label = classifier.classes_[max_label_index]\n","metadata":{"execution":{"iopub.status.busy":"2023-12-20T09:39:52.991451Z","iopub.execute_input":"2023-12-20T09:39:52.991777Z","iopub.status.idle":"2023-12-20T09:39:53.529266Z","shell.execute_reply.started":"2023-12-20T09:39:52.991747Z","shell.execute_reply":"2023-12-20T09:39:53.527408Z"},"trusted":true},"execution_count":34,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/543617254.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmax_label_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmax_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_label_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmax_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_label_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'TextClassificationPipeline' object has no attribute 'predict_proba'"],"ename":"AttributeError","evalue":"'TextClassificationPipeline' object has no attribute 'predict_proba'","output_type":"error"}]}]}